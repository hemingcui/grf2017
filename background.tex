\vspace{-.15in}\section{Research Background} 
\label{sec:background}\vspace{-.075in}


This section introduces the background of big-data 
frameworks (\S\ref{sec:bigdata}), sofware-based privacy techniques  
(\S\ref{sec:dft}), hardware-based privacy techniques (\S\ref{sec:sgx}), 
motivation of objectives (\S\ref{sec:motivation}), and related work 
(\S\ref{sec:others-work} and \S\ref{sec:my-work}).


\vspace{-.15in}\subsection{Big-data Computing Frameworks} 
\label{sec:bigdata}\vspace{-.075in}

Big-data frameworks (\eg Spark~\cite{nsdi12:spark}, 
DryadLINQ~\cite{osdi08:dryad}, MapReduce \cite{mapreduce}) are popular for 
computations on tremendous amounts of data. These frameworks provide 
self-defined functions (\eg, map and reduce) to let computation providors 
write their algorithms to perform queries or transformations on data, and these 
frameworks automatically apply the functions on the data stored across 
computers in parallel. To exchange intermediate results across hosts, shuffles 
operations are often invoked and sometimes they are performance bottlenecks in 
big-data frameworks. For instance, Spark~\cite{nsdi12:spark} has intensive data 
shuffling beteen its map and reduce stages.

% Many-to-many transformations (\eg \func{groupByKey}, \func{join}
% and \func{aggregateByKey}) are prevalent in these frameworks. Each many-to-many
% transformation takes many input records and generates many output records.
% Given an output record, extant data provenance 
% techniques~\cite{icse16:bigdebug,vldb15:titian,vldb16:output}, which track the 
% sequence of transformation operations for data records and can infer the input 
% records on a given output record, will
% report all input records going through this transformation, including many
% irrelevant input records that generate other output records.


To avoid excessive computation, many DISC systems adopt the lazy transformation 
approach~\cite{pig:vldb08,nsdi12:spark,osdi08:dryad}. Spark uses lazy 
transformations (\eg \func{map}) for efficiency, and calls to these 
transformations only create a new data structure called \func{RDD} with 
\func{lineage} (the sequence of transformation operations for a data record).
The real transformations are only triggered when collecting operations (\eg 
\func{collect}, \func{count}) are called. These collecting operations trigger 
transformations along lineages, where unnecessary computations are avoided. 
\textbf{Objective 1} (\chref{sec:kakute}) leverages the lazy transformation
feature in big-data frameworks to develop the new \lazyp technique.

\vspace{-.15in}\subsection{Software-based Privacy Techniques}
\label{sec:dft}\vspace{-.075in}

Data Flow Tracking (DFT) is a mandatory access control technique for preventing 
sensitive information leakage~\cite{dawn05:taint}. DFT attaches a tag to a 
variable (or object), and this tag will propagate throughout the computation at 
runtime. For example, a variable-level dataflow tracking will involve 
combinations of tags of two variables in each instruction, using an IOR 
operation. Different granularities of computation may incur different levels of 
computation overhead. Lower level (\eg byte-level) tracking will consume a lot 
of resources, as each byte of data in an DFT system has its own 
tags~\cite{libdft:vee12}. DFT has been applied to various areas, such as 
preventing sensitive information 
(\eg GPS data and contacts) leakage in cellphone~\cite{taintdroid:osdi10, 
cleanos:osdi12}, providing secure web services~\cite{cloudfence:raid13} and 
server programs~\cite{libdft:vee12}. To the best of our knowledge, no 
DFT system exists for big-data computing.
 
% Multiple research has been focusing on efficiency and applications of DFT.
% Shadowreplica~\cite{shadowreplica:ccs13} proposed to make use of the multicore 
% resources while SHIFT~\cite{hardwardtaint:isca08} suggests accelerating 
% dataflow tracking with hardware support. Several 
% research~\cite{mit07:coverage,fse12:dtam} adopts DFT for providing 
% debugging primitives to improve software reliability.


Complimentary to DFT, statistical techniques allow the aggregration of 
sensitive data while preserving the privacy of any individual one. These 
statistical techniques include k\-anonymization 
methods~\cite{kanonymity,icde06:ldiversity} or
differential privacy~\cite{gupt:sigmod12, pinq:sigmod09,airavat:nsdi10}, which 
enforce statistical bounds to prevent individual information leakage.
% Therefore, third-parties can
% not get sensitive data with different queries.

However, these statistical techniques are either not secure (k\-anonymization) 
or suffering from great losses of accuracy (differential privacy). A recent
work~\cite{differentialresult:vldb15} reported more than 30\% losses of accuracy 
when the security guarantee is high (the probability of leakages is low). In 
such case, a simple KMeans program will return centroids far from the accurate 
ones, and the accuracy loss rate is much larger than the training error rate 
which is several percents in practice. Overall, despite much effort, existing 
differential privacy techniques can only favor privacy or utility of results, 
but not both, and key reason is that these techniques lack a precise tracking 
of how sensitive data fields flow to query results, so they have to take a 
coarse-grained approach, which conservatively adds noise to all fields and 
records.


In practice, only some fields in a data record may be sensitive and it is too 
rigorous to make all fields inaccurate. Moreover, different data records may 
have various security levels. For example, in an Taobao order record 
$\langle$\v{time}, \v{userId}, \v{productID}$\rangle$, the \v{userId} field is 
sensitive and it must not be leaked, and different owners of movie rating 
records may demand different levels of protection for their 
data. \textbf{Objective 2} (\chref{sec:obj2}) 
proposes a novel fine-grained differential privacy technique, which combines  
the strengths of DFT and differential privacy.
% 4. They are not accurate and per-record, only some field are sensitive



\vspace{-.15in}\subsection{Hardware-based Privacy Techniques}
\label{sec:sgx}\vspace{-.075in}

Trusted Execution Environment (TEE) is a promising technique that
protects computation on cloud even through the operating system is
compromised. The program is running in a secure environment, and memory can not
be seen by malicious parties. For example, Intel-SGX~\cite{intel-sgx} runs 
programs
in a enclave, which is protected and can not be see by the system.

However, running programs in a enclave needs modifications to the original
programs, which needs a great effort and is error-prone. Recent
work~\cite{securekeeper,opaque:nsdi17} run Zookeeper and SparkSQL in enclaves,
and both of them rewrote codes running in enclaves using C++.
BigMatrix~\cite{bigmatrix:ccs17} proposes a secure and oblivious vectorization
abstraction for Python, but it also needs modifications to the original 
programs.
These methods causes two problems. First, modifications are necessary to run
programs in enclaves. Second, running C++ in JVM breaks the protections
provided Java.

\vspace{-.15in}\subsection{Motivation of objectives} 
\label{sec:motivation}\vspace{-.075in}
TBD.

\subsection{Related work by others} 
\label{sec:others-work}\vspace{-.075in}

\para{Computing on encrypted data}. Homomorphic 
encryption~\cite{fullmomo:stoc09,paillier,elgamal} is a
technique for performing computations on encryted data in untrusted 
environments. Homomorphic encryption contain two kinds: Fully 
homomorphic encryption (FHE) and partial 
homomorphic encryption.
Partial homomorphic encryption (\eg{} Additive Homomorphic 
Encryption~\cite{paillier})
incurs a much lower overhead compared with FHE. A evaluation~\cite{homo:eval} on
FHE shows a $10e9$ slowdown, which is acceptable in practice.
Systems that adopts PHE (\eg{} Monomi~\cite{monomi:vldb13},
Crypsis~\cite{crypsis:hotcloud14}, CryptDB~\cite{cryptdb:sosp11},
MrCrypt~\cite{mrcrypt:oospsla14})
reports a much better overhead, but it has limited expressiveness
(\eg{} SQL operators) and requires extra trusted servers for computations.
Seabed~\cite{seabed:osdi16} proposes asymmetric encryption schemes and reduces 
performance overhead
incur by AHE, but it still has limited expressiveness.

\subsection{Hardware-based Privacy-preserving Analytic}
Intel SGX is a promising technique to provide privacy-preserving analytic
in public clouds. Compared with software-based solutions, hardware-based 
solutions
incurs much lower overhead. TrustedDB~\cite{trusteddb:sigmod11} is a
hardware-based secure database.
VC3~\cite{vc3:sp15} proposes a secure distributed analytic platform
with read-write validations on Mapreduce~\cite{mapreduce}. 
Opaque~\cite{opaque:nsdi17}
supports secure and oblivious SQL operators on 
SparkSQL~\cite{sparksql:sigmod15}.
However, all these systems have limited expressiveness (\eg SQL operators), and
VC3 even needs to rewrite the program with C++. A recent 
work~\cite{oblivious:security16} proposes a oblivious machine leaning
framework on trusted processors.
BigMatrix~\cite{bigmatrix:ccs17} proposes an oblivious and secure vectorization
abstraction on python, but it has limited expressiveness and it needs to
rewrite the original program with this new abstraction.
Although BigMatrix provides guideline for
writing a oblivious program, but it would be a time-consuming and error-prone
process.

\vspace{-.15in}\subsection{Related work by the PI and co-I} 
\label{sec:my-work}\vspace{-.075in}
% 
% First emphasis debugging experience on concurrency. Program analysis.
% Then mention security exploits found in Woodpecker.
% Then mention runtime systems.

The PI is an expert on secure and reliable distributed 
systems~\cite{smt:cacm, cui:tern:osdi10, peregrine:sosp11,
parrot:sosp13, crane:sosp15, tripod:apsys16, kakute:acsac17, 
confluence:tpds17}. The PI's works are published in top conferences on systems 
(OSDI, SOSP, SOCC, TPDS, and ACSAC) and programming languages (PLDI and ASPLOS). 
The co-I is an expert on high-performance 
computing~\cite{powerrock,hwang,jessica,cheung,khokhar}, fault-tolerance~\cite{ 
sheng,shengdi1}, and VMs~\cite{rhymes,shengdi,jessica2}. The 
co-I's works are published in top systems conferences (Cluster '02, SC '13, 
and ICPADS '14) and journals (JPDC '00, TPDS '13, IEEE Tran. Computers '14). As 
preliminary works for this proposal, the PI and co-I have developed 
Kakute~\cite{kakute:acsac17} and TPDS~\cite{confluence:tpds17} (parts of 
\textbf{Objective 1}). 


