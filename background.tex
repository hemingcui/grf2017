\vspace{-.15in}\section{Research Background} 
\label{sec:background}\vspace{-.075in}

This section introduces the background of relevant techniquest in this proposal.

% This section presents the background of consensus (\S\ref{sec:consensus}) and 
% datacenter computing infrastructures (\S\ref{sec:datacenter}), motivation of 
% objectives (\S\ref{sec:motivation}), others' related work 
% (\S\ref{sec:others-work}), and the PI and co-I's related work 
% (\S\ref{sec:my-work}).

\vspace{-.15in}\subsection{Big-data Computing Frameworks} 
\label{sec:bigdata}\vspace{-.075in}

DISC frameworks (\eg Spark~\cite{nsdi12:spark},
DryadLINQ~\cite{osdi08:dryad}, MapReduce \cite{mapreduce}) are popular for 
computations
on tremendous
amounts of data, to finish tasks like data analysis and machine learning.
Computations are split across hosts and run in parallel, such that
computation resources are efficiently used.
% Therefore, computation powers are beyond the limit of one single machine, as a 
large-scale
% cluster of machines can cooperate to process one computation task.
Shuffles are frequent and sometimes are performance bottlenecks in DISC.
% in these systems.
% Spark~\cite{nsdi12:spark} has data shuffling during
% reduce stages, graph processing frameworks (\eg Pregal~\cite{sigmod10:pregel})
% uses messages for node updates, and Parameter Server~\cite{osdi14:pserver} has
% parameter updates.

% Many-to-many transformations (\eg \func{groupByKey}, \func{join}
% and \func{aggregateByKey}) are prevalent in DISC. Each many-to-many
% transformation takes many input records and generates many output records.
% Given a buggy output record, extant data provenance 
% system~\cite{icse16:bigdebug,vldb15:titian,vldb16:output} will
% report all input records going through this transformation, including many
% irrelevant input records that generate other output records.


To avoid excessive computation, many DISC systems adopt the lazy transformation 
approach.
~\cite{pig:vldb08,nsdi12:spark,osdi08:dryad}.
Spark uses lazy transformations (\eg \func{map}) for efficiency,
and calls to these transformations only create a new data structure called 
\func{RDD} with \func{lineage}.
The real transformations are only triggered when collecting operations (\eg 
\func{collect},
\func{count}) are called. These collecting operations trigger transformations 
along
lineages, where unnecessary computations are avoided. 
\kakute (\chref{sec:kakute}) leverages the lazy transformation
feature in DISC to present its new \lazyp technique.

\vspace{-.15in}\subsection{DFT and Diff Privacy}
\label{sec:dft}\vspace{-.075in}

Information Flow Tracking is initially proposed for preventing sensitive 
information
leakage~\cite{dawn05:taint}.
IFT attaches a tag to a variable (or object),
and this tag will propagate throughout the computation.
For example, a variable-level dataflow tracking will involve combinations of
tags of two variables in each instruction, using an IOR operation.
Different granularities of computation may incur different levels
of computation overhead. Lower level (\eg byte-level) tracking will consume
a lot of resources, as each byte of data in an IFT system has its own 
tags~\cite{libdft:vee12}.
 
Multiple research has been focusing on efficiency and applications of IFT.
Shadowreplica~\cite{shadowreplica:ccs13} proposed to make use of the multicore 
resources while SHIFT~\cite{hardwardtaint:isca08}
suggests accelerating dataflow tracking with hardware support.
Several research~\cite{mit07:coverage,fse12:dtam} adopts IFT for providing 
debugging primitives
to improve software reliability.
IFT has been applied to various areas, such as preventing sensitive information 
(\eg GPS data and contacts)
leakage in cellphone~\cite{taintdroid:osdi10, cleanos:osdi12}, providing secure
cloud services~\cite{cloudfence:raid13} and server program 
runtime~\cite{libdft:vee12}.
To the best of
our knowledge, no IFT system exists for big-data.

\vspace{-.15in}\subsection{Intel SGX}
\label{sec:sgx}\vspace{-.075in}

Trusted Execution Environment (TEE) is a promising technique that
protects computation on cloud even through the operating system is
compromised. The program is running in a secure environment, and memory can not
be seen by malicious parties. For example, Intel-SGX~\cite{intel-sgx} runs 
programs
in a enclave, which is protected and can not be see by the system.

However, running programs in a enclave needs modifications to the original
programs, which needs a great effort and is error-prone. Recent
work~\cite{securekeeper,opaque:nsdi17} run Zookeeper and SparkSQL in enclaves,
and both of them rewrote codes running in enclaves using C++.
BigMatrix~\cite{bigmatrix:ccs17} proposes a secure and oblivious vectorization
abstraction for Python, but it also needs modifications to the original 
programs.
These methods causes two problems. First, modifications are necessary to run
programs in enclaves. Second, running C++ in JVM breaks the protections
provided Java.

% \vspace{-.15in}\subsection{Motivation of objectives} 
% \label{sec:motivation}\vspace{-.075in}



% \vspace{-.15in}% hack, for the gaia footnote.
\subsection{Related work by others} 
\label{sec:others-work}\vspace{-.075in}

\subsection{Software-based Privacy-preserving Analytic}
Homomorphic encryption~\cite{fullmomo:stoc09,paillier,elgamal} is a 
software-based
techniques for protecting data in untrusted environments. Homomorphic encryption
can be sorted as two kinds: Fully homomorphic encryption (FHE) and partial 
homomorphic encryption.
Partial homomorphic encryption (\eg{} Additive Homomorphic 
Encryption~\cite{paillier})
incurs a much lower overhead compared with FHE. A evaluation~\cite{homo:eval} on
FHE shows a $10e9$ slowdown, which is acceptable in practice.
Systems that adopts PHE (\eg{} Monomi~\cite{monomi:vldb13},
Crypsis~\cite{crypsis:hotcloud14}, CryptDB~\cite{cryptdb:sosp11},
MrCrypt~\cite{mrcrypt:oospsla14})
reports a much better overhead, but it has limited expressiveness
(\eg{} SQL operators) and requires extra trusted servers for computations.
Seabed~\cite{seabed:osdi16} proposes asymmetric encryption schemes and reduces 
performance overhead
incur by AHE, but it still has limited expressiveness.

\subsection{Hardware-based Privacy-preserving Analytic}
Intel SGX is a promising technique to provide privacy-preserving analytic
in public clouds. Compared with software-based solutions, hardware-based 
solutions
incurs much lower overhead. TrustedDB~\cite{trusteddb:sigmod11} is a
hardware-based secure database.
VC3~\cite{vc3:sp15} proposes a secure distributed analytic platform
with read-write validations on Mapreduce~\cite{mapreduce}. 
Opaque~\cite{opaque:nsdi17}
supports secure and oblivious SQL operators on 
SparkSQL~\cite{sparksql:sigmod15}.
However, all these systems have limited expressiveness (\eg SQL operators), and
VC3 even needs to rewrite the program with C++. A recent 
work~\cite{oblivious:security16} proposes a oblivious machine leaning
framework on trusted processors.
BigMatrix~\cite{bigmatrix:ccs17} proposes an oblivious and secure vectorization
abstraction on python, but it has limited expressiveness and it needs to
rewrite the original program with this new abstraction.
Although BigMatrix provides guideline for
writing a oblivious program, but it would be a time-consuming and error-prone
process.

\vspace{-.15in}\subsection{Related work by the PI and co-I} 
\label{sec:my-work}\vspace{-.075in}
% 
% First emphasis debugging experience on concurrency. Program analysis.
% Then mention security exploits found in Woodpecker.
% Then mention runtime systems.

The PI is an expert on secure and reliable distributed 
systems~\cite{smt:cacm, cui:tern:osdi10, peregrine:sosp11,
parrot:sosp13, crane:sosp15, tripod:apsys16, kakute:acsac17, 
confluence:tpds17}. The PI's works are published in top conferences on systems 
(OSDI, SOSP, SOCC, TPDS, and ACSAC) and programming languages (PLDI and ASPLOS). 
The co-I is an expert on high-performance 
computing~\cite{powerrock,hwang,jessica,cheung,khokhar}, fault-tolerance~\cite{ 
sheng,shengdi1}, and VMs~\cite{rhymes,shengdi,jessica2}. The 
co-I's works are published in top systems conferences (Cluster '02, SC '13, 
and ICPADS '14) and journals (JPDC '00, TPDS '13, IEEE Tran. Computers '14). As 
preliminary works for this proposal, the PI and co-I have developed 
Kakute~\cite{kakute:acsac17} and TPDS~\cite{confluence:tpds17} (parts of 
\textbf{Objective 1}). 


